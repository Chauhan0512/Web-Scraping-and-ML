{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a01862-df25-4677-b23f-678cb39ab5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\yash\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yash\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\yash\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\yash\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: xgboost in c:\\users\\yash\\anaconda3\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yash\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yash\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yash\\anaconda3\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yash\\anaconda3\\lib\\site-packages (from requests) (2025.7.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yash\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\yash\\anaconda3\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yash\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yash\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 numpy scikit-learn xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "273a85a3-5218-4bb7-82c8-a57cb1e1914d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of rounds (comma-separated, e.g., 2,4,6,8,...):  2,4,6,8,10,12,14,16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Generating dataset for SM4 round 2 with 100,000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 2 - Generating 100k samples: 100%|██████████| 50000/50000 [00:38<00:00, 1303.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Training XGBoost classifier...\n",
      "[✓] Round 2 - Accuracy: 100.00%\n",
      "\n",
      "[+] Generating dataset for SM4 round 4 with 100,000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 4 - Generating 100k samples: 100%|██████████| 50000/50000 [00:44<00:00, 1125.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Training XGBoost classifier...\n",
      "[✓] Round 4 - Accuracy: 99.94%\n",
      "\n",
      "[+] Generating dataset for SM4 round 6 with 100,000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 6 - Generating 100k samples: 100%|██████████| 50000/50000 [00:51<00:00, 975.07it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Training XGBoost classifier...\n",
      "[✓] Round 6 - Accuracy: 49.35%\n",
      "\n",
      "[+] Generating dataset for SM4 round 8 with 100,000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 8 - Generating 100k samples: 100%|██████████| 50000/50000 [00:57<00:00, 865.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Training XGBoost classifier...\n",
      "[✓] Round 8 - Accuracy: 49.13%\n",
      "\n",
      "[+] Generating dataset for SM4 round 10 with 100,000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 10 - Generating 100k samples: 100%|██████████| 50000/50000 [00:53<00:00, 928.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Training XGBoost classifier...\n",
      "[✓] Round 10 - Accuracy: 48.34%\n",
      "\n",
      "[+] Generating dataset for SM4 round 12 with 100,000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 12 - Generating 100k samples: 100%|██████████| 50000/50000 [00:39<00:00, 1278.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Training XGBoost classifier...\n",
      "[✓] Round 12 - Accuracy: 48.86%\n",
      "\n",
      "[+] Generating dataset for SM4 round 14 with 100,000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 14 - Generating 100k samples: 100%|██████████| 50000/50000 [00:42<00:00, 1173.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Training XGBoost classifier...\n",
      "[✓] Round 14 - Accuracy: 49.12%\n",
      "\n",
      "[+] Generating dataset for SM4 round 16 with 100,000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Round 16 - Generating 100k samples: 100%|██████████| 50000/50000 [00:46<00:00, 1079.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Training XGBoost classifier...\n",
      "[✓] Round 16 - Accuracy: 48.62%\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import random\n",
    "from sm4 import encrypt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----------------- Web Scraping -----------------\n",
    "def scrape_wikipedia_text(url, max_length=500):\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    text = ''\n",
    "    for p in paragraphs:\n",
    "        text += p.get_text()\n",
    "        if len(text) > max_length:\n",
    "            break\n",
    "    return text[:max_length]\n",
    "\n",
    "# ----------------- Helpers -----------------\n",
    "def string_to_ascii_decimal(text, length=16):\n",
    "    decimal = 0\n",
    "    for i in text:\n",
    "        decimal <<= 8\n",
    "        decimal += ord(i)\n",
    "    if length < 16:\n",
    "        decimal <<= 8 * (16 - length)\n",
    "    return decimal\n",
    "\n",
    "def flip_first_bit(text):\n",
    "    first_char = text[0]\n",
    "    flipped_char = chr(ord(first_char) ^ 0b00000001)\n",
    "    return flipped_char + text[1:]\n",
    "\n",
    "def text_to_block(text):\n",
    "    return string_to_ascii_decimal(text[:16], min(16, len(text)))\n",
    "\n",
    "# ----------------- Data Generation -----------------\n",
    "def generate_data(rounds, num_samples=50000):\n",
    "    url = \"https://en.wikipedia.org/wiki/India\"\n",
    "    text = scrape_wikipedia_text(url)\n",
    "    p1 = text[:16]\n",
    "    p1_delta = flip_first_bit(p1)\n",
    "\n",
    "    # 2 * 50,000 = 100,000 samples (256 bits each)\n",
    "    data = np.zeros((2 * num_samples, 256), dtype=np.uint8)\n",
    "    labels = np.zeros((2 * num_samples,), dtype=np.uint8)\n",
    "\n",
    "    with open(f\"cipher_p1_and_p1delta_r{rounds}.bin\", 'wb') as f1, open(f\"cipher_p1_and_p2_r{rounds}.bin\", 'wb') as f2:\n",
    "        for i in tqdm(range(num_samples), desc=f\"Round {rounds} - Generating 100k samples\"):\n",
    "            key = random.randint(0, 2**128 - 1)\n",
    "\n",
    "            pt1 = text_to_block(p1)\n",
    "            pt1_delta = text_to_block(p1_delta)\n",
    "            pt2_text = ''.join(random.sample(text, len(p1)))\n",
    "            pt2 = text_to_block(pt2_text)\n",
    "\n",
    "            ct1, _ = encrypt(pt1, key, rounds)\n",
    "            ct2a, _ = encrypt(pt1_delta, key, rounds)\n",
    "            ct2b, _ = encrypt(pt2, key, rounds)\n",
    "\n",
    "            f1.write(ct1.to_bytes(16, 'big'))\n",
    "            f1.write(ct2a.to_bytes(16, 'big'))\n",
    "            f2.write(ct1.to_bytes(16, 'big'))\n",
    "            f2.write(ct2b.to_bytes(16, 'big'))\n",
    "\n",
    "            data[i] = np.unpackbits(np.frombuffer(ct1.to_bytes(16, 'big') + ct2a.to_bytes(16, 'big'), dtype=np.uint8))\n",
    "            labels[i] = 1\n",
    "            data[num_samples + i] = np.unpackbits(np.frombuffer(ct1.to_bytes(16, 'big') + ct2b.to_bytes(16, 'big'), dtype=np.uint8))\n",
    "            labels[num_samples + i] = 0\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "# ----------------- ML Training -----------------\n",
    "def run_xgboost(data, labels):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "    model = XGBClassifier(eval_metric='logloss', verbosity=0)\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    return acc\n",
    "\n",
    "# ----------------- Main Logic -----------------\n",
    "if __name__ == \"__main__\":\n",
    "    rounds_input = input(\"Enter number of rounds (comma-separated, e.g., 2,4,6,8,...): \")\n",
    "    try:\n",
    "        rounds_list = [int(r.strip()) for r in rounds_input.split(',')]\n",
    "        for r in rounds_list:\n",
    "            if not (1 <= r <= 32):\n",
    "                raise ValueError(f\"Round {r} out of valid range.\")\n",
    "    except:\n",
    "        print(\"Invalid input. Please enter rounds like 2,4,6,... (values 1–32).\")\n",
    "        exit()\n",
    "\n",
    "    for rounds in rounds_list:\n",
    "        print(f\"\\n[+] Generating dataset for SM4 round {rounds} with 100,000 samples...\")\n",
    "        data, labels = generate_data(rounds, num_samples=50000)\n",
    "\n",
    "        print(\"[*] Training XGBoost classifier...\")\n",
    "        accuracy = run_xgboost(data, labels)\n",
    "        print(f\"[✓] Round {rounds} - Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5467ae-4a72-4df4-b89f-20ccdc0d78a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
